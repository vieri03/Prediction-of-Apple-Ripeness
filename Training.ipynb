{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training",
      "provenance": [],
      "authorship_tag": "ABX9TyOWY1nlFQF5s9TWCMjup9XF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vieri03/Prediction-of-Apple-Ripeness/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/forwardpropagation_backpropagation_gradientdescent/"
      ],
      "metadata": {
        "id": "sy3U6j_VbnYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H788muri9OSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set manual seed\n",
        "torch.manual_seed(2)\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3PCsbFr9S7g",
        "outputId": "613cc5b4-150c-4373-9867-bd255bd6cebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/training4.csv')"
      ],
      "metadata": {
        "id": "gM788VrD9WBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df=pd.DataFrame(input,columns=['contrast-1-0',\t'ASM-1-0',\t'energy-1-0',\t'homogeneity-1-0',\t'dissimilarity-1-0',\t\n",
        "#                                  'contrast-1-45',\t'ASM-1-45',\t'energy-1-45',\t'homogeneity-1-45',\t'dissimilarity-1-45',\n",
        "#                                  'contrast-1-90',\t'ASM-1-90',\t'energy-1-90',\t'homogeneity-1-90',\t'dissimilarity-1-90',\n",
        "#                                  'contrast-1-135',\t'ASM-1-135',\t'energy-1-135',\t'homogeneity-1-135',\t'dissimilarity-1-135',\t\n",
        "#                                  'contrast-2-0',\t'ASM-2-0',\t'energy-2-0',\t'homogeneity-2-0',\t'dissimilarity-2-0',\t\n",
        "#                                  'contrast-2-45',\t'ASM-2-45',\t'energy-2-45',\t'homogeneity-2-45',\t'dissimilarity-2-45',\t\n",
        "#                                  'contrast-2-90',\t'ASM-2-90',\t'energy-2-90',\t'homogeneity-2-90',\t'dissimilarity-2-90',\t\n",
        "#                                  'contrast-2-135',\t'ASM-2-135',\t'energy-2-135',\t'homogeneity-2-135',\t'dissimilarity-2-135',\n",
        "#                                  'contrast-3-0',\t'ASM-3-0',\t'energy-3-0',\t'homogeneity-3-0',\t'dissimilarity-3-0',\n",
        "#                                  'contrast-3-45',\t'ASM-3-45',\t'energy-3-45',\t'homogeneity-3-45',\t'dissimilarity-3-45',\t\n",
        "#                                  'contrast-3-90',\t'ASM-3-90',\t'energy-3-90',\t'homogeneity-3-90',\t'dissimilarity-3-90',\t\n",
        "#                                  'contrast-3-135',\t'ASM-3-135',\t'energy-3-135',\t'homogeneity-3-135',\t'dissimilarity-3-135',\n",
        "#                                  'L',\t'a*',\t'b*',\t'output'])\n",
        "df=pd.DataFrame(input,columns=['ASM-1-0', 'energy-1-0', 'homogeneity-1-0', 'dissimilarity-1-0', 'ASM-1-45', 'energy-1-45', 'homogeneity-1-45', 'ASM-1-90', \n",
        "                                'energy-1-90', 'homogeneity-1-90', 'ASM-1-135', 'energy-1-135', 'homogeneity-1-135', 'ASM-2-0', 'energy-2-0', 'ASM-2-45',\n",
        "                               'energy-2-45', 'ASM-2-90', 'energy-2-90', 'ASM-2-135', 'energy-2-135', 'homogeneity-2-135', 'ASM-3-0', 'energy-3-0',\n",
        "                               'homogeneity-3-0', 'dissimilarity-3-0', 'ASM-3-45', 'energy-3-45', 'homogeneity-3-45', 'dissimilarity-3-45', 'ASM-3-90', \n",
        "                               'energy-3-90', 'homogeneity-3-90', 'dissimilarity-3-90', 'ASM-3-135', 'energy-3-135', 'homogeneity-3-135', 'output'])"
      ],
      "metadata": {
        "id": "0AfHBfIg9XjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_7mNFf-WKBZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "2bd93ac1-7bf2-4338-b623-376c00f028b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ASM-1-0  energy-1-0  homogeneity-1-0  dissimilarity-1-0  ASM-1-45  \\\n",
              "0  0.843234    0.918278         0.540631           0.919790  0.836704   \n",
              "1  0.855369    0.924861         0.537015           0.927022  0.852039   \n",
              "2  0.696395    0.834503         0.579816           0.846154  0.707826   \n",
              "3  0.724393    0.851113         0.571729           0.861275  0.732030   \n",
              "4  0.819716    0.905382         0.543327           0.916502  0.812081   \n",
              "\n",
              "   energy-1-45  homogeneity-1-45  ASM-1-90  energy-1-90  homogeneity-1-90  \\\n",
              "0     0.914715          0.542604  0.836704     0.914715          0.542604   \n",
              "1     0.923059          0.538001  0.852039     0.923059          0.538001   \n",
              "2     0.841324          0.576068  0.707826     0.841324          0.576068   \n",
              "3     0.855588          0.570151  0.732030     0.855588          0.570151   \n",
              "4     0.901155          0.544576  0.812081     0.901155          0.544576   \n",
              "\n",
              "   ...  homogeneity-3-45  dissimilarity-3-45  ASM-3-90  energy-3-90  \\\n",
              "0  ...          0.543590            0.913872  0.833462     0.912941   \n",
              "1  ...          0.538988            0.923077  0.848724     0.921262   \n",
              "2  ...          0.581328            0.842867  0.694049     0.833096   \n",
              "3  ...          0.569757            0.865220  0.729845     0.854310   \n",
              "4  ...          0.547403            0.908613  0.804866     0.897143   \n",
              "\n",
              "   homogeneity-3-90  dissimilarity-3-90  ASM-3-135  energy-3-135  \\\n",
              "0          0.543590            0.913872   0.836704      0.914715   \n",
              "1          0.538988            0.923077   0.852039      0.923059   \n",
              "2          0.581328            0.842867   0.707826      0.841324   \n",
              "3          0.569757            0.865220   0.732030      0.855588   \n",
              "4          0.547403            0.908613   0.812081      0.901155   \n",
              "\n",
              "   homogeneity-3-135  output  \n",
              "0           0.542604       1  \n",
              "1           0.538001       1  \n",
              "2           0.576068       1  \n",
              "3           0.570151       1  \n",
              "4           0.544576       0  \n",
              "\n",
              "[5 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7efc4a80-dfda-452e-a6a5-d12279e2a9a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASM-1-0</th>\n",
              "      <th>energy-1-0</th>\n",
              "      <th>homogeneity-1-0</th>\n",
              "      <th>dissimilarity-1-0</th>\n",
              "      <th>ASM-1-45</th>\n",
              "      <th>energy-1-45</th>\n",
              "      <th>homogeneity-1-45</th>\n",
              "      <th>ASM-1-90</th>\n",
              "      <th>energy-1-90</th>\n",
              "      <th>homogeneity-1-90</th>\n",
              "      <th>...</th>\n",
              "      <th>homogeneity-3-45</th>\n",
              "      <th>dissimilarity-3-45</th>\n",
              "      <th>ASM-3-90</th>\n",
              "      <th>energy-3-90</th>\n",
              "      <th>homogeneity-3-90</th>\n",
              "      <th>dissimilarity-3-90</th>\n",
              "      <th>ASM-3-135</th>\n",
              "      <th>energy-3-135</th>\n",
              "      <th>homogeneity-3-135</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.843234</td>\n",
              "      <td>0.918278</td>\n",
              "      <td>0.540631</td>\n",
              "      <td>0.919790</td>\n",
              "      <td>0.836704</td>\n",
              "      <td>0.914715</td>\n",
              "      <td>0.542604</td>\n",
              "      <td>0.836704</td>\n",
              "      <td>0.914715</td>\n",
              "      <td>0.542604</td>\n",
              "      <td>...</td>\n",
              "      <td>0.543590</td>\n",
              "      <td>0.913872</td>\n",
              "      <td>0.833462</td>\n",
              "      <td>0.912941</td>\n",
              "      <td>0.543590</td>\n",
              "      <td>0.913872</td>\n",
              "      <td>0.836704</td>\n",
              "      <td>0.914715</td>\n",
              "      <td>0.542604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.855369</td>\n",
              "      <td>0.924861</td>\n",
              "      <td>0.537015</td>\n",
              "      <td>0.927022</td>\n",
              "      <td>0.852039</td>\n",
              "      <td>0.923059</td>\n",
              "      <td>0.538001</td>\n",
              "      <td>0.852039</td>\n",
              "      <td>0.923059</td>\n",
              "      <td>0.538001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538988</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.848724</td>\n",
              "      <td>0.921262</td>\n",
              "      <td>0.538988</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.852039</td>\n",
              "      <td>0.923059</td>\n",
              "      <td>0.538001</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.696395</td>\n",
              "      <td>0.834503</td>\n",
              "      <td>0.579816</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.707826</td>\n",
              "      <td>0.841324</td>\n",
              "      <td>0.576068</td>\n",
              "      <td>0.707826</td>\n",
              "      <td>0.841324</td>\n",
              "      <td>0.576068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.581328</td>\n",
              "      <td>0.842867</td>\n",
              "      <td>0.694049</td>\n",
              "      <td>0.833096</td>\n",
              "      <td>0.581328</td>\n",
              "      <td>0.842867</td>\n",
              "      <td>0.707826</td>\n",
              "      <td>0.841324</td>\n",
              "      <td>0.576068</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.724393</td>\n",
              "      <td>0.851113</td>\n",
              "      <td>0.571729</td>\n",
              "      <td>0.861275</td>\n",
              "      <td>0.732030</td>\n",
              "      <td>0.855588</td>\n",
              "      <td>0.570151</td>\n",
              "      <td>0.732030</td>\n",
              "      <td>0.855588</td>\n",
              "      <td>0.570151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.569757</td>\n",
              "      <td>0.865220</td>\n",
              "      <td>0.729845</td>\n",
              "      <td>0.854310</td>\n",
              "      <td>0.569757</td>\n",
              "      <td>0.865220</td>\n",
              "      <td>0.732030</td>\n",
              "      <td>0.855588</td>\n",
              "      <td>0.570151</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.819716</td>\n",
              "      <td>0.905382</td>\n",
              "      <td>0.543327</td>\n",
              "      <td>0.916502</td>\n",
              "      <td>0.812081</td>\n",
              "      <td>0.901155</td>\n",
              "      <td>0.544576</td>\n",
              "      <td>0.812081</td>\n",
              "      <td>0.901155</td>\n",
              "      <td>0.544576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.547403</td>\n",
              "      <td>0.908613</td>\n",
              "      <td>0.804866</td>\n",
              "      <td>0.897143</td>\n",
              "      <td>0.547403</td>\n",
              "      <td>0.908613</td>\n",
              "      <td>0.812081</td>\n",
              "      <td>0.901155</td>\n",
              "      <td>0.544576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7efc4a80-dfda-452e-a6a5-d12279e2a9a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7efc4a80-dfda-452e-a6a5-d12279e2a9a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7efc4a80-dfda-452e-a6a5-d12279e2a9a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = df.iloc[:,:63].values\n",
        "x = df.iloc[:,:37].values\n",
        "X = torch.tensor(x, dtype=torch.float)"
      ],
      "metadata": {
        "id": "OJKdfGWoOW8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.iloc[:,-1]\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = torch.tensor(y.reshape(-1, 1), dtype=torch.float)"
      ],
      "metadata": {
        "id": "xtQKZs-eZgwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.size())\n",
        "# print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5L8t4T9VdqZ",
        "outputId": "df0263ac-18ef-499e-9f89-cab0566a103f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 37])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FNN(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Dimensions for input, hidden and output\n",
        "        # self.input_dim = 63\n",
        "        self.input_dim = 37\n",
        "        self.hidden_dim = 12\n",
        "        self.output_dim = 1\n",
        "\n",
        "        # Learning rate definition\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "        # Our parameters (weights)\n",
        "        # w1: 63 x 21\n",
        "        self.w1 = torch.randn(self.input_dim, self.hidden_dim)\n",
        "\n",
        "        # w2: 21 x 1\n",
        "        self.w2 = torch.randn(self.hidden_dim, self.output_dim)\n",
        "\n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + torch.exp(-s))\n",
        "\n",
        "    def sigmoid_first_order_derivative(self, s):\n",
        "        return s * (1 - s)\n",
        "\n",
        "    # Forward propagation\n",
        "    def forward(self, X):\n",
        "        # First linear layer\n",
        "        self.y1 = torch.matmul(X, self.w1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
        "\n",
        "        # First non-linearity\n",
        "        self.y2 = self.sigmoid(self.y1)\n",
        "\n",
        "        # Second linear layer\n",
        "        self.y3 = torch.matmul(self.y2, self.w2)\n",
        "\n",
        "        # Second non-linearity\n",
        "        y4 = self.sigmoid(self.y3)\n",
        "        return y4\n",
        "\n",
        "    # Backward propagation\n",
        "    def backward(self, X, l, y4):\n",
        "        # Derivative of binary cross entropy cost w.r.t. final output y4\n",
        "        self.dC_dy4 = y4 - l\n",
        "\n",
        "        '''\n",
        "        Gradients for w2: partial derivative of cost w.r.t. w2\n",
        "        dC/dw2\n",
        "        '''\n",
        "        self.dy4_dy3 = self.sigmoid_first_order_derivative(y4)\n",
        "        self.dy3_dw2 = self.y2\n",
        "\n",
        "        # Y4 delta: dC_dy4 dy4_dy3\n",
        "        self.y4_delta = self.dC_dy4 * self.dy4_dy3\n",
        "\n",
        "        # This is our gradients for w1: dC_dy4 dy4_dy3 dy3_dw2\n",
        "        self.dC_dw2 = torch.matmul(torch.t(self.dy3_dw2), self.y4_delta)\n",
        "\n",
        "        '''\n",
        "        Gradients for w1: partial derivative of cost w.r.t w1\n",
        "        dC/dw1\n",
        "        '''\n",
        "        self.dy3_dy2 = self.w2\n",
        "        self.dy2_dy1 = self.sigmoid_first_order_derivative(self.y2)\n",
        "\n",
        "        # Y2 delta: (dC_dy4 dy4_dy3) dy3_dy2 dy2_dy1\n",
        "        self.y2_delta = torch.matmul(self.y4_delta, torch.t(self.dy3_dy2)) * self.dy2_dy1\n",
        "\n",
        "        # Gradients for w1: (dC_dy4 dy4_dy3) dy3_dy2 dy2_dy1 dy1_dw1\n",
        "        self.dC_dw1 = torch.matmul(torch.t(X), self.y2_delta)\n",
        "\n",
        "        # Gradient descent on the weights from our 2 linear layers\n",
        "        self.w1 -= self.learning_rate * self.dC_dw1\n",
        "        self.w2 -= self.learning_rate * self.dC_dw2\n",
        "\n",
        "    def train(self, X, l):\n",
        "        # Forward propagation\n",
        "        y4 = self.forward(X)\n",
        "\n",
        "        # Backward propagation and gradient descent\n",
        "        self.backward(X, l, y4)"
      ],
      "metadata": {
        "id": "_lC9CCghbAVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model class and assign it to our model object\n",
        "model = FNN()\n",
        "\n",
        "# Loss list for plotting of loss behaviour\n",
        "loss_lst = []\n",
        "\n",
        "# Number of times we want our FNN to look at all 100 samples we have, 100 implies looking through 100x\n",
        "num_epochs = 1001\n",
        "\n",
        "# Let's train our model with 100 epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Get our predictions\n",
        "    y_hat = model(X)\n",
        "\n",
        "    # Cross entropy loss, remember this can never be negative by nature of the equation\n",
        "    # But it does not mean the loss can't be negative for other loss functions\n",
        "    cross_entropy_loss = -(y * torch.log(y_hat) + (1 - y) * torch.log(1 - y_hat))\n",
        "\n",
        "    # We have to take cross entropy loss over all our samples, 100 in this 2-class dataset\n",
        "    mean_cross_entropy_loss = torch.mean(cross_entropy_loss).detach().item()\n",
        "\n",
        "    total = y_hat.shape[0]\n",
        "    predicted = (y_hat > 0.5).float()\n",
        "    correct = (predicted == y).sum()\n",
        "    acc = correct/total\n",
        "\n",
        "    # Print our mean cross entropy loss\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {} | Loss: {} | Accuracy:{}'.format(epoch, mean_cross_entropy_loss, acc))\n",
        "    loss_lst.append(mean_cross_entropy_loss)\n",
        "\n",
        "    # (1) Forward propagation: to get our predictions to pass to our cross entropy loss function\n",
        "    # (2) Back propagation: get our partial derivatives w.r.t. parameters (gradients)\n",
        "    # (3) Gradient Descent: update our weights with our gradients\n",
        "    model.train(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpqEXmcrbOVL",
        "outputId": "b6a3299b-f513-4d3d-bf85-787bc3bb8a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 1.5578001737594604 | Accuracy:0.5199999809265137\n",
            "Epoch 10 | Loss: 0.7047811150550842 | Accuracy:0.5199999809265137\n",
            "Epoch 20 | Loss: 0.701494574546814 | Accuracy:0.5\n",
            "Epoch 30 | Loss: 0.6999766826629639 | Accuracy:0.5299999713897705\n",
            "Epoch 40 | Loss: 0.6984874606132507 | Accuracy:0.5199999809265137\n",
            "Epoch 50 | Loss: 0.6970735788345337 | Accuracy:0.5199999809265137\n",
            "Epoch 60 | Loss: 0.6957711577415466 | Accuracy:0.5199999809265137\n",
            "Epoch 70 | Loss: 0.6946002244949341 | Accuracy:0.5199999809265137\n",
            "Epoch 80 | Loss: 0.6935651302337646 | Accuracy:0.5199999809265137\n",
            "Epoch 90 | Loss: 0.692659854888916 | Accuracy:0.5199999809265137\n",
            "Epoch 100 | Loss: 0.6918719410896301 | Accuracy:0.5199999809265137\n",
            "Epoch 110 | Loss: 0.6911868453025818 | Accuracy:0.5199999809265137\n",
            "Epoch 120 | Loss: 0.6905896663665771 | Accuracy:0.5199999809265137\n",
            "Epoch 130 | Loss: 0.6900664567947388 | Accuracy:0.5600000023841858\n",
            "Epoch 140 | Loss: 0.6896052360534668 | Accuracy:0.5600000023841858\n",
            "Epoch 150 | Loss: 0.6891956925392151 | Accuracy:0.5600000023841858\n",
            "Epoch 160 | Loss: 0.6888294219970703 | Accuracy:0.5699999928474426\n",
            "Epoch 170 | Loss: 0.6884991526603699 | Accuracy:0.5799999833106995\n",
            "Epoch 180 | Loss: 0.6881991624832153 | Accuracy:0.5600000023841858\n",
            "Epoch 190 | Loss: 0.687924861907959 | Accuracy:0.550000011920929\n",
            "Epoch 200 | Loss: 0.6876723766326904 | Accuracy:0.5400000214576721\n",
            "Epoch 210 | Loss: 0.687438428401947 | Accuracy:0.5600000023841858\n",
            "Epoch 220 | Loss: 0.6872203946113586 | Accuracy:0.550000011920929\n",
            "Epoch 230 | Loss: 0.6870161294937134 | Accuracy:0.550000011920929\n",
            "Epoch 240 | Loss: 0.6868240237236023 | Accuracy:0.550000011920929\n",
            "Epoch 250 | Loss: 0.6866422891616821 | Accuracy:0.5400000214576721\n",
            "Epoch 260 | Loss: 0.6864699721336365 | Accuracy:0.5299999713897705\n",
            "Epoch 270 | Loss: 0.6863056421279907 | Accuracy:0.5299999713897705\n",
            "Epoch 280 | Loss: 0.6861487030982971 | Accuracy:0.5299999713897705\n",
            "Epoch 290 | Loss: 0.6859982013702393 | Accuracy:0.5199999809265137\n",
            "Epoch 300 | Loss: 0.6858534216880798 | Accuracy:0.5199999809265137\n",
            "Epoch 310 | Loss: 0.6857138276100159 | Accuracy:0.5199999809265137\n",
            "Epoch 320 | Loss: 0.6855789422988892 | Accuracy:0.5199999809265137\n",
            "Epoch 330 | Loss: 0.6854482293128967 | Accuracy:0.5199999809265137\n",
            "Epoch 340 | Loss: 0.6853213310241699 | Accuracy:0.5400000214576721\n",
            "Epoch 350 | Loss: 0.6851978898048401 | Accuracy:0.5299999713897705\n",
            "Epoch 360 | Loss: 0.6850774884223938 | Accuracy:0.5299999713897705\n",
            "Epoch 370 | Loss: 0.684960126876831 | Accuracy:0.5299999713897705\n",
            "Epoch 380 | Loss: 0.6848451495170593 | Accuracy:0.5400000214576721\n",
            "Epoch 390 | Loss: 0.6847324967384338 | Accuracy:0.5400000214576721\n",
            "Epoch 400 | Loss: 0.6846221089363098 | Accuracy:0.550000011920929\n",
            "Epoch 410 | Loss: 0.6845134496688843 | Accuracy:0.550000011920929\n",
            "Epoch 420 | Loss: 0.6844068169593811 | Accuracy:0.550000011920929\n",
            "Epoch 430 | Loss: 0.6843016147613525 | Accuracy:0.5400000214576721\n",
            "Epoch 440 | Loss: 0.6841980218887329 | Accuracy:0.5400000214576721\n",
            "Epoch 450 | Loss: 0.6840957403182983 | Accuracy:0.5400000214576721\n",
            "Epoch 460 | Loss: 0.6839948296546936 | Accuracy:0.5400000214576721\n",
            "Epoch 470 | Loss: 0.6838951110839844 | Accuracy:0.5400000214576721\n",
            "Epoch 480 | Loss: 0.6837964653968811 | Accuracy:0.5600000023841858\n",
            "Epoch 490 | Loss: 0.6836989521980286 | Accuracy:0.5600000023841858\n",
            "Epoch 500 | Loss: 0.683602511882782 | Accuracy:0.5600000023841858\n",
            "Epoch 510 | Loss: 0.6835071444511414 | Accuracy:0.5699999928474426\n",
            "Epoch 520 | Loss: 0.6834129095077515 | Accuracy:0.5699999928474426\n",
            "Epoch 530 | Loss: 0.6833196878433228 | Accuracy:0.5600000023841858\n",
            "Epoch 540 | Loss: 0.6832277178764343 | Accuracy:0.5600000023841858\n",
            "Epoch 550 | Loss: 0.6831368207931519 | Accuracy:0.550000011920929\n",
            "Epoch 560 | Loss: 0.6830471754074097 | Accuracy:0.550000011920929\n",
            "Epoch 570 | Loss: 0.6829589009284973 | Accuracy:0.550000011920929\n",
            "Epoch 580 | Loss: 0.6828719973564148 | Accuracy:0.550000011920929\n",
            "Epoch 590 | Loss: 0.6827866435050964 | Accuracy:0.550000011920929\n",
            "Epoch 600 | Loss: 0.6827027797698975 | Accuracy:0.550000011920929\n",
            "Epoch 610 | Loss: 0.6826207041740417 | Accuracy:0.550000011920929\n",
            "Epoch 620 | Loss: 0.6825402975082397 | Accuracy:0.550000011920929\n",
            "Epoch 630 | Loss: 0.6824616193771362 | Accuracy:0.550000011920929\n",
            "Epoch 640 | Loss: 0.6823848485946655 | Accuracy:0.550000011920929\n",
            "Epoch 650 | Loss: 0.6823099255561829 | Accuracy:0.550000011920929\n",
            "Epoch 660 | Loss: 0.6822370290756226 | Accuracy:0.550000011920929\n",
            "Epoch 670 | Loss: 0.6821660399436951 | Accuracy:0.550000011920929\n",
            "Epoch 680 | Loss: 0.6820969581604004 | Accuracy:0.550000011920929\n",
            "Epoch 690 | Loss: 0.6820299029350281 | Accuracy:0.550000011920929\n",
            "Epoch 700 | Loss: 0.6819646954536438 | Accuracy:0.550000011920929\n",
            "Epoch 710 | Loss: 0.6819015741348267 | Accuracy:0.550000011920929\n",
            "Epoch 720 | Loss: 0.681840181350708 | Accuracy:0.550000011920929\n",
            "Epoch 730 | Loss: 0.6817806959152222 | Accuracy:0.550000011920929\n",
            "Epoch 740 | Loss: 0.68172287940979 | Accuracy:0.550000011920929\n",
            "Epoch 750 | Loss: 0.6816668510437012 | Accuracy:0.550000011920929\n",
            "Epoch 760 | Loss: 0.681612491607666 | Accuracy:0.550000011920929\n",
            "Epoch 770 | Loss: 0.681559681892395 | Accuracy:0.550000011920929\n",
            "Epoch 780 | Loss: 0.6815084218978882 | Accuracy:0.550000011920929\n",
            "Epoch 790 | Loss: 0.6814586520195007 | Accuracy:0.550000011920929\n",
            "Epoch 800 | Loss: 0.6814103126525879 | Accuracy:0.550000011920929\n",
            "Epoch 810 | Loss: 0.6813633441925049 | Accuracy:0.550000011920929\n",
            "Epoch 820 | Loss: 0.6813175678253174 | Accuracy:0.550000011920929\n",
            "Epoch 830 | Loss: 0.6812732219696045 | Accuracy:0.550000011920929\n",
            "Epoch 840 | Loss: 0.6812300086021423 | Accuracy:0.550000011920929\n",
            "Epoch 850 | Loss: 0.6811878681182861 | Accuracy:0.550000011920929\n",
            "Epoch 860 | Loss: 0.6811469197273254 | Accuracy:0.550000011920929\n",
            "Epoch 870 | Loss: 0.6811070442199707 | Accuracy:0.550000011920929\n",
            "Epoch 880 | Loss: 0.6810681819915771 | Accuracy:0.550000011920929\n",
            "Epoch 890 | Loss: 0.6810302734375 | Accuracy:0.550000011920929\n",
            "Epoch 900 | Loss: 0.6809933185577393 | Accuracy:0.550000011920929\n",
            "Epoch 910 | Loss: 0.6809574365615845 | Accuracy:0.550000011920929\n",
            "Epoch 920 | Loss: 0.6809223294258118 | Accuracy:0.550000011920929\n",
            "Epoch 930 | Loss: 0.6808879971504211 | Accuracy:0.550000011920929\n",
            "Epoch 940 | Loss: 0.6808544993400574 | Accuracy:0.550000011920929\n",
            "Epoch 950 | Loss: 0.6808218359947205 | Accuracy:0.550000011920929\n",
            "Epoch 960 | Loss: 0.6807899475097656 | Accuracy:0.550000011920929\n",
            "Epoch 970 | Loss: 0.6807587146759033 | Accuracy:0.550000011920929\n",
            "Epoch 980 | Loss: 0.6807283163070679 | Accuracy:0.550000011920929\n",
            "Epoch 990 | Loss: 0.680698573589325 | Accuracy:0.550000011920929\n",
            "Epoch 1000 | Loss: 0.6806694865226746 | Accuracy:0.550000011920929\n"
          ]
        }
      ]
    }
  ]
}